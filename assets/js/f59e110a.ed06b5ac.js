"use strict";(globalThis.webpackChunkwebsite=globalThis.webpackChunkwebsite||[]).push([[8973],{2235:(e,i,n)=>{n.r(i),n.d(i,{assets:()=>u,contentTitle:()=>h,default:()=>m,frontMatter:()=>c,metadata:()=>s,toc:()=>g});const s=JSON.parse('{"id":"papers/y2025/nov/20251104","title":"2025-11-04 papers review","description":"1. Every Activation Boosted","source":"@site/docs/papers/y2025/nov/20251104.md","sourceDirName":"papers/y2025/nov","slug":"/papers/y2025/nov/20251104","permalink":"/docs/papers/y2025/nov/20251104","draft":false,"unlisted":false,"editUrl":"https://github.com/logicbaron/logicbaron.github.io/tree/dev/docs/papers/y2025/nov/20251104.md","tags":[],"version":"current","frontMatter":{},"sidebar":"Y2025Sidebar","previous":{"title":"2025-11-01 papers review","permalink":"/docs/papers/y2025/nov/20251101"}}');var l=n(4848),a=n(8453);const r=n.p+"assets/images/blog_20251104_img0-c57258906a0ba07b840f331e0a74751f.png",o=n.p+"assets/images/blog_20251104_img1-86dda9336fe00e9302ff6d79083927b9.png",d=n.p+"assets/images/blog_20251104_img2-997bfa8ca4c5433f781a64bdb9456ba6.png",t=n.p+"assets/images/blog_20251104_img3-68e881592c46700fd85f77beeddf81c3.png",c={},h="2025-11-04 papers review",u={},g=[{value:"1. Every Activation Boosted",id:"1-every-activation-boosted",level:2},{value:"Scaling General Reasoner to 1 Trillion Open Language Foundation",id:"scaling-general-reasoner-to-1-trillion-open-language-foundation",level:3},{value:"2. World Simulation with Video Foundation Models for Physical AI <code>nvidia</code>",id:"2-world-simulation-with-video-foundation-models-for-physical-ai-nvidia",level:2},{value:"3. Towards Universal Video Retrieval <code>alibaba</code>",id:"3-towards-universal-video-retrieval-alibaba",level:2},{value:"Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum",id:"generalizing-video-embedding-via-synthesized-multimodal-pyramid-curriculum",level:3},{value:"4. Do Vision-Language Models Measure Up?",id:"4-do-vision-language-models-measure-up",level:2},{value:"Benchmarking Visual Measurement Reading with MeasureBench",id:"benchmarking-visual-measurement-reading-with-measurebench",level:3},{value:"5. Data-Efficient RLVR via Off-Policy Influence Guidance",id:"5-data-efficient-rlvr-via-off-policy-influence-guidance",level:2}];function p(e){const i={a:"a",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,l.jsxs)(l.Fragment,{children:[(0,l.jsx)(i.header,{children:(0,l.jsx)(i.h1,{id:"2025-11-04-papers-review",children:"2025-11-04 papers review"})}),"\n",(0,l.jsxs)(i.h2,{id:"1-every-activation-boosted",children:["1. ",(0,l.jsx)(i.a,{href:"https://huggingface.co/papers/2510.22115",children:"Every Activation Boosted"})]}),"\n",(0,l.jsx)(i.h3,{id:"scaling-general-reasoner-to-1-trillion-open-language-foundation",children:"Scaling General Reasoner to 1 Trillion Open Language Foundation"}),"\n",(0,l.jsxs)(i.p,{children:[(0,l.jsx)(i.code,{children:"Inclusion AI"}),"\uc5d0\uc11c \uc81c\uc548\ud558\ub294 ",(0,l.jsx)(i.strong,{children:"Ling 2.0"})," \ubaa8\ub378."]}),"\n",(0,l.jsx)(i.p,{children:"MOE with high-sparsity \uc0ac\uc6a9."}),"\n",(0,l.jsxs)(i.h2,{id:"2-world-simulation-with-video-foundation-models-for-physical-ai-nvidia",children:["2. ",(0,l.jsx)(i.a,{href:"https://huggingface.co/papers/2511.00062",children:"World Simulation with Video Foundation Models for Physical AI"})," ",(0,l.jsx)(i.code,{children:"nvidia"})]}),"\n",(0,l.jsxs)(i.p,{children:["\ub85c\ubd07\uc774\ub098 \uc790\uc728\uc8fc\ud589\ucc28\uc640 \uac19\uc740 Physical AI \uc2dc\uc2a4\ud15c\uc740 \uc2e4\uc81c \ud658\uacbd\uc5d0\uc11c \ud6c8\ub828\ud558\uae30 \uc5b4\ub824\uc6cc\uc11c, ",(0,l.jsx)(i.strong,{children:"World sSimulator"}),"\uc758 \uc218\uc694\uac00 \ub192\ub2e4."]}),"\n",(0,l.jsxs)(i.ul,{children:["\n",(0,l.jsx)(i.li,{children:"\uc2e4\uc81c \ubb3c\ub9ac \uc138\uacc4\ub97c \ub300\uccb4\ud560 \uc218 \uc788\ub294 \uace0\ud488\uc9c8\uc758 \uac00\uc0c1 \ud658\uacbd \uc2dc\ubbac\ub808\uc774\ud130 \ud544\uc694."}),"\n"]}),"\n",(0,l.jsxs)(i.p,{children:["Flow-based \ube44\ub514\uc624 \uc6d4\ub4dc \ubaa8\ub378 ",(0,l.jsx)(i.strong,{children:"Cosmos-Predict-2.5"})," \uc81c\uc548."]}),"\n",(0,l.jsx)(i.p,{children:"Curated Video Clip 0.2B\uac1c\ub85c \uc120\ubcc4. Physical AI\uc5d0 \ud2b9\ud654\ub41c VLM\uc778 Cosmo-Reason1\uc744 \ud14d\uc2a4\ud2b8 \uc778\ucf54\ub354\ub85c \uc0ac\uc6a9\ud574\uc11c \ub354 \ud48d\ubd80\ud55c Captioning \ub370\uc774\ud130 \uc0dd\uc131."}),"\n",(0,l.jsx)("div",{style:{textAlign:"center"},children:(0,l.jsx)("img",{src:r,style:{width:500}})}),"\n",(0,l.jsx)(i.p,{children:"\ubaa8\ub378 \ud559\uc2b5"}),"\n",(0,l.jsxs)(i.ul,{children:["\n",(0,l.jsx)(i.li,{children:"Diffusion Transformer \uad6c\uc870 \uae30\ubc18."}),"\n",(0,l.jsx)(i.li,{children:"relative positional embeddings \uc0ac\uc6a9."}),"\n",(0,l.jsxs)(i.li,{children:["Elucidated Diffusion Model \ub300\uc2e0 Flow matching \ubc29\uc2dd \uc0ac\uc6a9.","\n",(0,l.jsxs)(i.ul,{children:["\n",(0,l.jsx)(i.li,{children:"Cosmos-Predict1 \ubaa8\ub378\uc774 \uc0ac\uc6a9\ud55c EDM \ubc29\uc2dd\uc740  diffusion \uc18d\ub3c4\ub294 \uc2dc\uac04\uc5d0 \ub9de\ucdb0 \uc77c\uc815. \ud45c\uc900 \uac00\uc6b0\uc2dc\uc548 \uae30\ubc18 \uc5d0\ub7ec \uc81c\uac70."}),"\n",(0,l.jsx)(i.li,{children:"Flow matching \ubc29\uc2dd\uc744 \ub3c4\uc785\ud55c Cosmos-Predict2.5 \ubaa8\ub378\uc740 \ub124\ud2b8\uc6cc\ud06c\uac00 diffusion \uacfc\uc815\uc744 \uc18d\ub3c4\uc5d0 \ub9de\ucdb0 \uc0dd\uc131\ud568."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)("div",{style:{textAlign:"center"},children:(0,l.jsx)("img",{src:o,style:{width:500}})}),"\n",(0,l.jsxs)(i.h2,{id:"3-towards-universal-video-retrieval-alibaba",children:["3. ",(0,l.jsx)(i.a,{href:"https://huggingface.co/papers/2510.27571",children:"Towards Universal Video Retrieval"})," ",(0,l.jsx)(i.code,{children:"alibaba"})]}),"\n",(0,l.jsx)(i.h3,{id:"generalizing-video-embedding-via-synthesized-multimodal-pyramid-curriculum",children:"Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum"}),"\n",(0,l.jsx)(i.p,{children:"\uae30\uc874 \ube44\ub514\uc624 \uac80\uc0c9 \ud328\ub7ec\ub2e4\uc784\uc740 Coarse-grained \ud14d\uc2a4\ud2b8 \uac80\uc0c9\uc5d0 \ud3b8\ud5a5\ub418\uc5b4 \uc788\uc74c. Fine-grained, Long-context, composed \ucffc\ub9ac \uae30\ubc18 \ube44\ub514\uc624 \uac80\uc0c9 \ub2a5\ub825\uc744 \uac16\ucd98 \ubaa8\ub378 \ud544\uc694."}),"\n",(0,l.jsxs)(i.ul,{children:["\n",(0,l.jsx)(i.li,{children:"16\uac1c \ub370\uc774\ud130\uc151\uc73c\ub85c '\ubcf4\ud3b8\uc131' \ud655\ubcf4\ub41c \ubca4\uce58\ub9c8\ud06c \uad6c\ucd95"}),"\n",(0,l.jsxs)(i.li,{children:["\uc9c4\ub2e8 \uacb0\uacfc\uc5d0 \uae30\ubc18\ud574 \uace0\ud488\uc9c8 \ub370\uc774\ud130 \ud569\uc131","\n",(0,l.jsxs)(i.ul,{children:["\n",(0,l.jsx)(i.li,{children:"Multi-granular Quality Control: \uc6d0\ubcf8 \ub370\uc774\ud130\uc5d0\uc11c \ub178\uc774\uc988 \uc81c\uac70."}),"\n",(0,l.jsx)(i.li,{children:"Multi-dimensional Information Enrichment: MLLM\uc744 \uc774\uc6a9\ud574\uc11c \uae30\uc874 \uc815\ubcf4\ub85c\ubd80\ud130 \uace0\ud488\uc9c8 \ucea1\uc158 \uc2e0\uaddc \uc0dd\uc131."}),"\n",(0,l.jsx)(i.li,{children:"Multimodal Task Extending: \uc2e4\uc81c \uac80\uc0c9 \uc2dc\ub098\ub9ac\uc624\uc5d0 \ud544\uc694\ud55c \ub2e4\uc591\ud55c \uc791\uc5c5 \ud615\uc2dd \ub370\uc774\ud130 \ud569\uc131."}),"\n"]}),"\n"]}),"\n",(0,l.jsxs)(i.li,{children:["Modality Pyramid \ucee4\ub9ac\ud058\ub7fc\uc744 \uc0ac\uc6a9\ud574 \ubaa8\ub378 \ud559\uc2b5.","\n",(0,l.jsxs)(i.ul,{children:["\n",(0,l.jsx)(i.li,{children:"Modality Pyramid \ucee4\ub9ac\ud058\ub7fc: fundamental data -> Domain specific data\ub85c \ud559\uc2b5\ud558\ub294 \ud53c\ub77c\ubbf8\ub4dc \ud615\ud0dc \ud559\uc2b5 \uc6cc\ud06c \ud50c\ub85c\uc6b0 \uc0ac\uc6a9."}),"\n"]}),"\n"]}),"\n"]}),"\n",(0,l.jsx)("div",{style:{textAlign:"center"},children:(0,l.jsx)("img",{src:d,style:{width:500}})}),"\n",(0,l.jsx)("div",{style:{textAlign:"center"},children:(0,l.jsx)("img",{src:t,style:{width:500}})}),"\n",(0,l.jsx)(i.p,{children:"\uae30\uc874 \ubaa8\ub378\ub4e4\uc774 \uc2e0\uaddc \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uc798 \ub3d9\uc791\ud558\uc9c0 \uc54a\uc74c + \uc0c8\ub85c \ud559\uc2b5\ud55c \ubaa8\ub378\uc774 \uc2e0\uaddc \ubca4\uce58\ub9c8\ud06c\uc5d0\uc11c \uc88b\uc740 \uc131\ub2a5 \ubcf4\uc774\ub294 \uac83 \ud655\uc778."}),"\n",(0,l.jsx)(i.p,{children:"\uc694\uc998 \uc2dc\ub300\uc5d0 \ubb38\uc81c\ub97c \ud574\uacb0\ud558\ub294 \ubc95, \ud504\ub808\uc784\uc6cc\ud06c \uc790\uccb4\uc5d0 \uc758\ubbf8\uac00 \uc788\ub2e4\uace0 \uc0dd\uac01\ub428."}),"\n",(0,l.jsxs)(i.h2,{id:"4-do-vision-language-models-measure-up",children:["4. ",(0,l.jsx)(i.a,{href:"https://huggingface.co/papers/2510.26865",children:"Do Vision-Language Models Measure Up?"})]}),"\n",(0,l.jsx)(i.h3,{id:"benchmarking-visual-measurement-reading-with-measurebench",children:"Benchmarking Visual Measurement Reading with MeasureBench"}),"\n",(0,l.jsx)(i.p,{children:"VLM\uc740 \ubcf5\uc7a1\ud55c \ucd94\ub860 \uc791\uc5c5\uc5d0\uc11c\ub294 \uc88b\uc740 \uc131\ub2a5\uc744 \ubcf4\uc774\uc9c0\ub9cc, \uc628\ub3c4\uacc4\uc758 \ub208\uae08 \uc77d\uae30\uc640 \uac19\uc740 \ub2e8\uc21c\ud558\uace0 \uc138\ubc00\ud55c \uc791\uc5c5\uc5d0\uc11c\ub294 \ub180\ub77c\uc6b8 \uc815\ub3c4\ub85c \ub0ae\uc740 \uc131\ub2a5\uc744 \ubcf4\uc784."}),"\n",(0,l.jsx)(i.p,{children:"\uc774\ub294 industry level\uc5d0\uc11c\ub294 \uaf64 \uc2ec\uac01\ud55c \ubb38\uc81c. gemini-2.5-pro\uc870\ucc28 30.3% \uc815\ub3c4 \uc815\ud655\ub3c4\uc5d0 \uadf8\uce68."}),"\n",(0,l.jsx)(i.p,{children:"\uacc4\uce21 \uc7a5\ube44 \uae30\uc900, \ubaa8\ub378\ub4e4\uc740 \ub2e8\uc704\ub97c \uc77d\ub294 OCR \uc131\ub2a5\uc740 \ub9e4\uc6b0 \uc88b\uc558\uc74c. \uadf8\ub7ec\ub098 \ud3ec\uc778\ud130, \uc561\uccb4\uc758 \uc704\uce58\uc640 \uac19\uc740 \uc9c0\uce68\uc758 \uc815\ud655\ud55c \uc704\uce58\ub97c \uc778\uc9c0\ud558\uc9c0 \ubabb\ud55c\ub2e4."}),"\n",(0,l.jsx)(i.p,{children:"\ud2b9\ud788 \ubcf5\ud569\uc7a5\ube44\uc5d0 \uc788\uc5b4\uc11c\ub294 0% \uc758 \uc815\ud655\ub3c4\uc784."}),"\n",(0,l.jsxs)(i.h2,{id:"5-data-efficient-rlvr-via-off-policy-influence-guidance",children:["5. ",(0,l.jsx)(i.a,{href:"https://huggingface.co/papers/2510.26491",children:"Data-Efficient RLVR via Off-Policy Influence Guidance"})]}),"\n",(0,l.jsx)(i.p,{children:"RLVR \ud559\uc2b5\uc5d0\uc11c \ub370\uc774\ud130 \uc120\ud0dd \ud6a8\uc728\uc131\uc744 \ub192\uc774\ub824\ub294 \ub17c\ubb38."}),"\n",(0,l.jsx)(i.p,{children:"Influence Function\uc744 \uc774\uc6a9\ud574 \uac01 \ub370\uc774\ud130\uac00 \ud559\uc2b5 \ubaa9\ud45c\uc5d0 \uc5bc\ub9c8\ub098 \uae30\uc5ec\ud558\ub294\uc9c0 \ucd94\uc815. LLM\uc758 online rollout cost\uac00 \ub108\ubb34 \ud06c\uae30 \ub584\ubb38\uc5d0, \uc0ac\uc804 \uc218\uc9d1\ub41c offline trajectory\ub97c \uc0ac\uc6a9\ud558\ub294 off-policy influence estimation\uc744 \ub3c4\uc785."}),"\n",(0,l.jsx)(i.p,{children:"\uacb0\uacfc\uc801\uc73c\ub85c 7B \ubaa8\ub378\uae4c\uc9c0\uc758 \uc2e4\ud5d8\uc5d0\uc11c \ud6c8\ub828\uc744 \ud06c\uac8c \ud6a8\uc728\ud654\uc2dc\ud0b4."}),"\n",(0,l.jsxs)(i.ol,{children:["\n",(0,l.jsx)(i.li,{children:"\uac12\ube44\uc2fc \uc2e4\uc2dc\uac04 rollout \uc5c6\uc774 \ub370\uc774\ud130 \uc601\ud5a5\ub825\uc744 \ucd94\uc815\ud558\ub294 offline influence estimation"}),"\n",(0,l.jsx)(i.li,{children:"\uace0\ucc28\uc6d0 gradient\ub97c \ud6a8\uc728\uc801\uc73c\ub85c \uc555\ucd95\ud558\ub294 sparse random projection"}),"\n",(0,l.jsx)(i.li,{children:"\ub450 \uae30\uc220\uc744 \uacb0\ud568\ud55c \uc0c8\ub85c\uc6b4 RLVR \ud559\uc2b5 \ud504\ub808\uc784\uc6cc\ud06c \uc81c\uc548."}),"\n"]})]})}function m(e={}){const{wrapper:i}={...(0,a.R)(),...e.components};return i?(0,l.jsx)(i,{...e,children:(0,l.jsx)(p,{...e})}):p(e)}},8453:(e,i,n)=>{n.d(i,{R:()=>r,x:()=>o});var s=n(6540);const l={},a=s.createContext(l);function r(e){const i=s.useContext(a);return s.useMemo(function(){return"function"==typeof e?e(i):{...i,...e}},[i,e])}function o(e){let i;return i=e.disableParentContext?"function"==typeof e.components?e.components(l):e.components||l:r(e.components),s.createElement(a.Provider,{value:i},e.children)}}}]);