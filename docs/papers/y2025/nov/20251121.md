import blog_20251121_img0 from './asset/blog_20251121_img0.png';

# 2025-11-21 papers review

## 1. [Agent0](https://huggingface.co/papers/2511.16043)
### Unleashing Self-Evolving Agents from Zero Data via Tool-Integrated Reasoning

LLM Agent가 수행하는 과제가 복잡할수록 학습시키기가 까다로워짐. 
- 학습 데이터 수집이 까다로움.
- self-evolution 방식은 inherent knowledge에 갇힘.

**Agent 0**제안. [Search self-play](/docs/papers/y2025/oct/20251027#2-search-self-play) 와 상당히 비슷한 느낌을 주는 논문이다.
- 경쟁 방식으로 모델을 학습.
  - Executor LLM은 도구를 활용해 문제를 해결하고, Curriculum LLM은 Executor LLM의 능력을 종합 평가해 적절한 문제를 만듬.
- inherent knoledge 한계를 벗어난 외부 tool 활용 능력을 통해 self-evolution 방식의 단점 보완.
- **Ambiguity-Dynamic Policy Optimization (ADPO)** 제안.
  - 강화학습 방법론. 크게 두가지 방식의 조정 도입.
  - 1. uncertainty가 높은 trajectory의 reward signal 약화.
  - 2. uncertainty가 높은 trajectory에 대해서는 exploration을 장려.

Result:
- mathematical reasoning에서 18%, general reasoning에서 24%라는 상당한 성능 향상
- 특히 복잡하고 어려운 문제에서 majority voting based pseudo-label 이 본질적인 라벨 노이즈를 포함하고 있다고 주장.

> Despite the improvement from self-consistency filtering, the $\mathcal{D}^{(t)}$ dataset still inevitably suffers from label noise, where the majority vote of a task's multiple rollouts may not represent the true optimal solution, especially for frontier tasks with high ambiguity and complexity.

## 2. [SAM 3D](https://huggingface.co/papers/2511.16624) `meta` 
### 3Dfy Anything in Images

https://ai.meta.com/sam3d/ try, try!

SAM의 다음 버전!
- segmentation뿐 아니라 단일 이미지에서 full 3D shape, layout and texture를 재구성.
- 3D data 부족이 이슈 였음.

데이터 파이프라인 구축
- LLM training과 같이 synthetic -> semi-synthetic -> real 데이터를 사용함.
- 사람이 직접 데이터를 만드는 과정 배제. model proposal 중 최적의 후보를 선택하고 약간의 조정만 추가.
- 결과적으로 1 million images - millions of 3d meshs pair 를 구축.

Results:
- human prefrence 에서 압도적으로 승리.
- 특히 인더스트리 레벨 활용도에서 높은 호평을 받고 있음.
- 다만, 내부적으로 테스트해본 결과 한국어 기준으로 fine-grained texture나 domain-specific feature를 잘 catch못하는 것 같다. 예를 들어서 제로콜라와 콜라를 이미지 내에서 구분하지는 못한다.


## 3. [MiMo-Embodied] `xiaomi`
### : X-Embodied Foundation Model Technical Report

SOTA 달성 in 
- Embodied AI 17개 벤치마크
- Autonomous Driving 12개 벤치마크

:::tip
**Emboided AI**

물리적 환경 내에 구현(embodied)되어 환경과 상호작용하며 학습하고 문제를 해결하는 인공지능 시스템. 로봇팔, 자율주행차, 드론과 같은 하드웨어에서 돌아가는 AI.
:::

## 4. [Nemotron Elastic](https://huggingface.co/papers/2511.16664) `nvidia`
### Towards Efficient Many-in-One Reasoning LLMs

LLM family
- 같은 기초 구조(Foundation Model)에서 Multiple Scales(parameter size), Deployment Objectives, Deployment Configurations 등에 따라 나뉘어지는 모델 집합.

LLM family 훈련이 매우 어려움.
- 대부분 전부 따로 훈련 시킴.
- 이로 인해서 비용과 시간이 너무 많이 들었음.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251121_img0} style={{width: 500}} />
</div>

**Nemotron Elastic**
- 하나의 parent 모델 내에 여러 개의 **nested submodel** 을 포함시키는 구조 제안.
- 두 단계의 훈련. 목적은 훈련 완료된 후 nested submodel 을 zero-shot 으로 활용할 수 있어야 함.
  - pruning-aware train: 나중에 모델의 일부만 동작할 것을 염두에 두고 layer dropout과 같은 regularization을 강하게 주어 parent 모델 학습.
  - routed submodel train : router를 사용해서 토큰 별 submodel routing. 

디테일이 조금 더 있는데, 당분간은 내 커리어와 거리가 멀 것 같아서 자세히 파악하지 않은 논문.

## 5. [EntroPIC](https://huggingface.co/papers/2511.15248) `tencent` 
### Towards Stable Long-Term Training of LLMs via Entropy Stabilization with Proportional-Integral Control

LLM 강화 학습시 exploiation-exploration trade-off 조절은 항상 어렵다.
- sub-optimal collpse를 막기 위해 stable exploration을 유지해야 함.
- 이를 위해선 응답의 entropy를 잘 조절해야하는데 일반적으로 어려움.
- entropy instability로 인해 policy oscillation 발생.

entropy를 동적으로 조정.
- 훈련 과정 entropy를 일정 수준으로 수렴시킴. (가능함을 먼저 증명함.)
- Positive/Negative samples의 loss coefficient를 동적으로 조절.
  - 엔트로피가 너무 클수록 강하게 제어.
- 결과적으로 일정한 수준의 exploration이 꾸준히 일어나게 됨.

논문에서는 꾸준히 exploration이 발생해야 exploiation도 더 좋아진다고 주장. (후반까지도.)