# 2025-11-01 papers review

## 1. [The End of Manual Decoding](https://huggingface.co/papers/2510.26697) `tencent`
### Towards Truly End-to-End Language Models 

LLM은 end-to-end 모델이지만 여전히 temperature, top-p 같은 하이퍼파라미터 세팅이 큰 영향을 미친다. static hyperparmeter 튜닝은 비용이 많이 들고, dynamic 수정이 어렵다.

논문에서는 **AutoDeco**라는 새로운 아키텍처를 제안. 표준 Transformer 모델에 가벼운 예측 헤드를 추가해서 매 생성 단계마다 다음 토큰의 logits 와 함께 context-specific temperature, top-p 값을 예측한다. 

제안된 구조에서는 hyperparameter 최적화가 자동으로 이루어진다. 정말로 사람이 튜닝해줘야하는 부분이 없으며 생성 과정에서 동적으로 최적의 temperature와 top-p 값이 적용된다는 점에서 의의를 가진다.

## 2. [PORTool](https://huggingface.co/papers/2510.26020) `apple`
### Tool-Use LLM Training with Rewarded Tree

현재 tool-use LLM 은 static dataset 으로 학습되어 정해진 도구 사용 루틴을 모방하는 경향이 있다. 이로 인해서 실제 상황에서 성능이 저하됨. 

이 현상의 핵심 이유는 trajectory 전체에 동일한 보상을 주는 기존 학습 방식. 실패한 궤적에서 유용한 중간 단계 판단, 결괃들이 평가받지 못함.

본 논문에서는 **PorTool** 이라는 강화 학습 방법을 제안. 하나의 쿼리에 대해 여러개의 rollout 을 생성해서 Tree 구조를 만듬. 각 단계마다 최종 답변의 정확도와 도구 호출의 성공 여부를 기준으로 단계별 보상을 할당한다. 그 후 fork-relative advantage 와 trajectory-relative advantage를 비교함.

즉 각 rollout의 중간 단계들이 1) 최종 결과의 우월성, 2) 중간 결과의 우월성으로 평가되는 것.

작은 모델(8B 이하) 기준으로 RL baseline 성능을 크게 능가. 특히 정확도 뿐만 아니라 효율성(도구 호출 횟수)도 개선됨.