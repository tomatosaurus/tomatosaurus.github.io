import blog_20251117_img0 from './asset/blog_20251117_img0.png';

# 2025-11-17 papers review


## 1. [Experience-Guided Adaptation of Inference-Time Reasoning Strategies](https://huggingface.co/papers/2511.11519)  `amazon`

<div style={{textAlign: 'center'}}>
 <img src={blog_20251117_img0} style={{width: 500}} />
</div>

## 2. [Don't Waste It](https://huggingface.co/papers/2511.10492) `meta`
### Guiding Generative Recommenders with Structured Human Priors via Multi-head Decoding

추천 시스템의 목표는 단순한 예측 정확도를 넘어 diversity, novelty, personalization과 같은 요소가 중요해지고 있음.

industry에서는 추천 시스템 개발을 위해 human priors를 축적해옴. 

기존에는 사용자 표현 벡터를 하나 사용했지만 제안하는 프레임 워크는 여러개의 벡터를 사용해서 사용자를 표현. 이를 통해 human priorf를 학습 과정에 직접 통합.

모델이 human prior를 이해하고 활용하여 추천 결과 생성.

## 3. [Virtual Width Networks](https://huggingface.co/papers/2511.11238) `bytedance`

hidden embedding size를 늘리면 모델의 표현령은 늘어나지만 연산량이 quadratic 증가. 이로 인해 hidden embedding size 늘리기는 상당히 어려운 문제.

MoE 같은 방법론에서는 모델의 연산량을 효율적으로 개선하지만, hidden embedidng size는 그대로이므로 내부 표현력이 그대로임.

본 논문은 모델 내부 임베딩 사이즈를 늘리면서, 연산 시의 임베딩 사이즈, 즉 backbone width 는 고정함. 이를 위해서 각 레이어마다 Generalized Hyper-Connection Module 을 도입. 임베딩 압축 후 연산이 진행됨.

결과적으로 모델 학습이 크게 빨라짐. 논문에서는 이를 모델이 입력 정보를 더 정교하고 다차원적으로 인코딩해서 빠르게 수렴할 수 있었다고 설명함.

## 4. [DiscoX](https://huggingface.co/papers/2511.10984) `bytedance`
### Benchmarking Discourse-Level Translation task in Expert Domains

:::note
**discourse-level**? 

단일 문장의 범위를 넘어선, 문장들 간의 관계나 전체 텍스트의 흐름을 다루는 수준의 언어학
:::

## 5. [MarsRL](https://huggingface.co/papers/2511.11373) `tencent`
### Advancing Multi-Agent Reasoning System via Reinforcement Learning with Agentic Pipeline Parallelism

