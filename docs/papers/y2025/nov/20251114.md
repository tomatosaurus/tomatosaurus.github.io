import blog_20251114_img0 from './asset/blog_20251114_img0.png';
import blog_20251114_img1 from './asset/blog_20251114_img1.png';

# 2025-11-14 papers review

## 1. [Black-Box On-Policy Distillation of Large Language Models](https://arxiv.org/abs/2511.10643) `microsoft`

Knowledge Distillation은 현대 LLM에서 중요한 과제.
- 기존 LLM KD는 주로 SFT기반으로 이루어짐.
- 최근 연구에서 on-policy RL이 주목받고 있음.
- 본 논문에서는 새로운 형태의 on-policy KD 방법론 제안.

:::note
SFT 방식은 학습 내내 완벽한 정답만 본다. 결국 같은 의미더라도 단어가 조금만 달라져도 틀렸다고 간주하면서, 응답 전체가 무너지게 된다.

예를 들어서, "오늘 날씨가" 라고 이야기하도록 학습한 모델이 "오늘 날씨는" 이라고 생성하는 순간 다음 단어를 이상하게 생성해버린다.

이 현상을 Exposure Bias라고 하며 SFT대신 RL이 LLM에서 주목받는 핵심이유. 노출된 단어에만 정상적으로 동작한다.

또한 RL 방식은 유연하고 창의적인 목표 설정이 가능하다.
:::

<div style={{textAlign: 'center'}}>
 <img src={blog_20251114_img0} style={{width: 500}} />
</div>

**GAD**: Generative Adversarial Distillation

- GAN 학습 방식을 on-policy RL에 적용.
- Discriminator가 Teacher 모델과 Student 모델의 답변을 구분함.
- Discriminator는 Loss 최소화를 목적으로 학습.
- Student 모델은 Discriminator의 점수를 reward로 강화학습.

학습 초기 안정성을 위해 SFT **warm-up** 진행.
- 개인적으로 이런 게 실제 환경에서는 정말 중요한 테크닉이라고 생각함.
- 1 epoch 의 Warming up. GAD 학습은 2 epoch
- 1 epcoh 동안 교사 모델의 행동을 cross-entropy loss로 완전히 복제하도록 학습됨.
- Ablation Study 결과, SFT warm-up 없으면 판별자가 너무 쉽게 정답을 구분해버려 paleatu 에서 벗어나지 못함.

## 2. [Depth Anything 3](https://huggingface.co/papers/2511.10647) `bytedance`
### Recovering the Visual Space from Any Views

<div style={{textAlign: 'center'}}>
 <img src={blog_20251114_img1} style={{width: 700}} />
</div>

이런거 하는 논문.

1. 단일 plain transformer, **Vanilla DINO** 적용.
2. 단 하나의 목표 **Depth-Ray**.
3. Teacher-student 방식

## 3. [Solving a Million-Step LLM Task with Zero Errors](https://huggingface.co/papers/2511.09030)

여러 단계로 이루어지는 복잡한 작업은 LLM에러율에 취약하다.
- LLM 에러율이 0.1%만 되어도, 수백 단계 이상이 필요한 작업이 되면 에러가 누적되어 매우 커지게 됨.
- 이로인해서 복잡한 단계에서 LLM을 활용하는데는 여전히 한계가 존재함.

기존 접근법과 한계
- 기존 접근법은 복잡한 작업을 한 번에 잘 완료하는 LLM 모델 개발에 집중됨.
- 일단 개발 비용이 비싸다.
- 또한, LLM 에러율의 누적이라는 근본적인 문제를 해결하지 못함. 
  - 새로운 모델도 어려워하는 더 복잡한 작업에서는 다시 문제가 발생할 것.

제안하는 방법: **더 안정적인 단일 프로세스**
- 결국 핵심은 각 세부 작업의 에러를 없애는 것.
- 각 세부 태스크에 강력한 검사 / 정제 작업을 적용.
- 작업의 각 단계에서 Error-correction, Red-flagging 수행.
  - Error-correction은 First-to-ahead-by-k 투표.
  - Red-flagging은 응답이 너무 길거나 형식이 잘못된 경우 제외.

## 4. [Music Flamingo](https://huggingface.co/papers/2511.10289) `nvidia`
### Scaling Music Understanding in Audio Language Models

음악 이해 능력 관련 연구. 관심 분야와 너무 달라 리스팅만.

Reward로는 규칙 또는 함수를 사용함. Format Reward, Accuracy Reward, Structured Thinking Reward. 

Accuracy Reward는 모델의 예측이 정답과 얼마나 문자열로써 일치하는지 확인함.


## 5. [AlphaResearch](https://huggingface.co/papers/2511.08522)
### Accelerating New Algorithm Discovery with Language Models

LLM은 기존 지식 활용에는 능숙하나 새로운 지식 탐구에는 여전히 약함.
- execution 기반 검증 실행 가능성에만 치중된 과학적으로 의미 없는 해법 제안.
- LLM 평가자를 도입하면 혁신적이지만, 실행은 불가능한 해법 제안.

AlphaResearch
- 가치 평가 / 구현 가능성 평가를 분리.
- 가치 평가.
  - 인간이 평가한 아이디어 가치를 사용해서 모델을 학습시킴.
  - 실제 피어 리뷰 데이터로 학습된 RewardModel(Qwen2.5)을 사용해 아이디어 자체의 가치를 먼저 평가.
- 구현 가능성 평가: 이후 평가된 아이디어를 코드로 구현하여 실행.

Result:
- 8개의 미해결 알고리즘 벤치 마크에서 2/8 승률 달성.
- "packing circles" 문제에서 best-of-known 알고리즘 발견.


## 6. [Benchmarking Diversity in Image Generation via Attribute-Conditional Human Evaluation](https://huggingface.co/papers/2511.10547) `google`

구글 내부에서 ImageGen3를 평가하다가 Diversity Metrics이 체감과 다르게 크게 개선되지 않아서 진행한 연구가 아닐까 싶다. (근데 이런걸로도 논문을 쓰는구나. 아쉬운 작업이 몇개 스쳐지나간다.)

보통 이미지 생성 모델은, 프롬프트는 일치하나 Diversity가 부족.
- homogeneous outputs 생성.
- 기존 다양성 지표는 이미지 임베딩에 의존함. 이게 과연 실제로 인간이 인지하는 다양성을 포착하고 있는가?
- 평가하기 쉽지 않음. 왜냐하면 다양성이 커지는 것과 control이 안되는 것의 구분이 어렵기 때문.

Proposed Method:
- Attribute-Conditional Human Evaluation 기반의 Robust Evaluation Methodology 제안.
- 인간 노가다.
- 특정 컨셉에 대해 인간이 속성 variation을 사전에 정의: "사과" 의 "색상" 은 "빨강", "초록", "노랑" 등이다.
- 인간 평가자가 모델이 생성한 이미지 셋에서 Attribute-Award Diversity가 얼마나 잘 표현되었는지 평가: Binomial Annotation

Result:
- Imagegen3 가 아주 성능이 좋았다.   https://www.imagine.art/ 여기서 테스트를 해보자.
- 기존 임베딩 기방 다양성 메트릭은 semantic diversity와 동떨어져 있다. -> 인간이 인지하는 다양성을 잘 반영하지 못한다.
  - DINOv2, CLIP, Gecko 등 다양한 임베딩을 검사해봤으나, 사람이 만든 평가 데이터와 상관관계가 거의 없었음.
- 더 의미론적이고 견고한 자동화된 메트릭 핊요성을 주장
- 논문은 다양성 측정을 위해서는 human annotation이 필수라고 주장.
- 한계점으로 지적한게 인간이 해야해서 자동화가 어렵다는 것. 

:::note
"Our rigorous comparison reveals that widely-used image embeddings (DINOv2, CLIP, Gecko) for diversity measurement fail to consistently align with human judgment, highlighting the need for more semantically grounded and robust automated metrics."

(번역): "우리의 엄격한 비교는 다양성 측정을 위해 널리 사용되는 이미지 임베딩(DINOv2, CLIP, Gecko)이 인간의 판단과 일관되게 일치하지 못함을 드러내며, 더 의미론적으로 근거 있고 견고한 자동화된 메트릭의 필요성을 강조한다."
:::




## 7. [One Small Step in Latent, One Giant Leap for Pixels: Fast Latent Upscale Adapter for Your Diffusion Models](https://huggingface.co/papers/2511.10629)

Diffusion Model은 학습된 해상도를 넘는 스케일을 잘 다루지 못함. 
- 일반적으로 2-step으로 접근. 이미지 생상 -> 고해상도 전환.
- Diffusion Model 자체의 초해상화는 연구가 적었다.

Proposed Method: **Latent Upscaler Adapter**
- Swin-transformer backbone
- VAE 디코딩 단계 이전의 latent vector에서 직접 초해상화를 수행.

Result:
- x2, x4 초해상화 수행. 속도는 당연히 훨씬 빨랐음..


## 8. [PAN](https://huggingface.co/papers/2511.09057)
### A World Model for General, Interactable, and Long-Horizon World Simulation

월드 모델은 볼 때마다 신기. **월드 모델의 선두 주자**를 앞으로 논문을 읽으면서 좀 보려고 한다.

https://panworld.ai/

구조
- Vision Encoder: 관측을 인코딩.
- World Model Backbone: 이전 vision latent state + 자연어 행동 -> new vision latent state 생성.
- Video Diffusion Decoder: 짧은 관측 영상 복원.

리뷰 : 물리 모델까지 적용된 최신 연구들에 비하면 그래도 단순한 편이라고 생각됨.

