import blog_20251120_img0 from './asset/blog_20251120_img0.png';
import blog_20251120_img1 from './asset/blog_20251120_img1.png';


# 2025-11-20 papers review

## 1. [Kandinsky 5.0](https://huggingface.co/papers/2511.14993)
### A Family of Foundation Models for Image and Video Generation

고해상도의 긴 영상을 만드는 건 Video Generation의 오랜 챌린지.
- 이슈 중 하나는 quadratic complexity.
- 긴 영상의 경우 일관성을 유지하기도 어려움.

**Kandisky 5.0**
- Diffusion Transformer 구조 채택.
- Neighborhood Adaptive Block-Level Attention (NABLA) 메커니즘을 도입.
  - 비디오 프레임 자체를 블록으로 나누어서 연산 처리해서 연산량 감소.
- Pre-training, SFT, RL-based Post-training의 다단계 학습 파이프라인과 TSCD를 결합한 Distillation 기법을 적용

Results:
- Motion Consistency, Visual Quality에서 기존 SOTA 모델보다 우수함을 입증
- Qwen2.5-VL 7B 텍스트 인코더의 Limited Context Length로 인해 일부 경쟁 모델 대비 Text-Visual Alignment에서 약간의 성능 저하가 확인
- 10초를 초과하는 시퀀스에서 복잡한 물리적 상호작용에 대한 Temporal Consistency는 여전히 개선이 필요

## 2. [VisPlay](https://huggingface.co/papers/2511.15661)
### Self-Evolving Vision-Language Models from Images

Self-evolving RL framework를 제안하며, 단일 VLM을 Image-Conditioned Questioner와 Multimodal Reasoner 두 역할로 나눕니다. 이들은 GRPO을 사용하여 공동으로 학습됩니다. Questioner는 Reasoner의 Uncertainty을 보상으로 받아 도전적인 질문을 생성하며, Reasoner는 Majority Voting으로 생성된 Pseudo-Label을 통해 학습

<div style={{textAlign: 'center'}}>
 <img src={blog_20251120_img0} style={{width: 500}} />
</div>

## 3.   What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity `meta`

AI agent가 빠르게 발전하고 있으나, Ai agent의 성공과 실패를 결정하는 핵심 요인은 명확히 밝혀지지 않음.

본 논문은 에이전트에게 기계학습 문제를 풀게하고 아이디어의 다양성이 높은 모델일수록 에이전트 성능이 향상됨을 통계적으로 확인함. 다양성 감소 싱능이 저하되었으며 특히 실행하지 못할 해법을 만드는 비중이 늠.

아이디어의 다양성은 모델이 제안하는 ML 모델 구조의 다양성의 엔트로피를 측정함. 즉, 초기에 다양한 모델을 고려할수록 다양성이 높은 것.

## 4. [MHR](https://huggingface.co/papers/2511.15586) `meta`
### Momentum Human Rig

Momentum 기반의 유연한 Rigging과 127개 관절의 상세한 포즈 파라미터 제어를 통합

나 왜 로봇이 생각나지.

## 5. [Mixture of States](https://huggingface.co/papers/2511.12207)
### Routing Token-Level Dynamics for Multimodal Generation

Multimodal Diffusion Model
- Multimodal Diffusion Model은 텍스트 인풋에 따라 이미지 생성, 편집 등을 수행함.
- 가장 대중적인 구조는 text encoder, image decoder 구조.
- text encoder 1회 동작 이후, image decoder는 diffusion model로 구성하여 timestep 만큼 시행됨.
- **image decoder는 timestep에 따라 동적인 feature를 가지게 되고 참조해야하는 정보도 달라지지만 텍스트 정보는 고정되어 비효율 발생.**
  - 예를 들어 초기에는 큰 구도, 나중에는 세밀한 feature를 잡아야하는데 텍스트 임베딩은 고정되어 있는거임.

기존 Solution
- cross-attention: 문제있다고 한 방식.
- MoT: 아래 그림에서 참조할수 있는 layer-layer 1:1 참조 방식.
  - MoT 역시 경직된 구조. 이미지 디코더가 필요한 정보를 적절하게 참조할 수 없다.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251120_img1} style={{width: 500}} />
</div>

Proposed Method: **MoS: Mixture of State**.
- 위 그림처럼, Router를 이용해서 이미지 디코더의 각 상태, 각 토큰을 참조해야 하는 텍스트 레이어와 유동적으로 연결.
- 2개의 Transformer Block으로 구성된 매우 작은 구조 사용함.
- 라우터는 텍스트 word embedding, image latent vector, time step을 입력받는다. ( 인코더, 디코더 통과 이전 초기 값 )
- 그 후, 텍스트 토큰별로 텍스트 레이어 x 이미지 레이어 연결 matrix 를 예측한다. 
- "갈색털을 가진 곰을 그려줘" 에서 "곰" 토큰은 이미지 디코더의 낮은 레이어와 연결되고 "갈색털" 은 이미지 디코더의 높은 레이어와 연결되는 식.