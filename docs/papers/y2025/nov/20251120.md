import blog_20251120_img0 from './asset/blog_20251120_img0.png';

# 2025-11-20 papers review

## 1. [Kandinsky 5.0](https://huggingface.co/papers/2511.14993)
### A Family of Foundation Models for Image and Video Generation

고해상도의 긴 영상을 만드는 건 Video Generation의 오랜 챌린지.
- 이슈 중 하나는 quadratic complexity.
- 긴 영상의 경우 일관성을 유지하기도 어려움.

**Kandisky 5.0**
- Diffusion Transformer 구조 채택.
- Neighborhood Adaptive Block-Level Attention (NABLA) 메커니즘을 도입.
  - 비디오 프레임 자체를 블록으로 나누어서 연산 처리해서 연산량 감소.
- Pre-training, SFT, RL-based Post-training의 다단계 학습 파이프라인과 TSCD를 결합한 Distillation 기법을 적용

Results:
- Motion Consistency, Visual Quality에서 기존 SOTA 모델보다 우수함을 입증
- Qwen2.5-VL 7B 텍스트 인코더의 Limited Context Length로 인해 일부 경쟁 모델 대비 Text-Visual Alignment에서 약간의 성능 저하가 확인
- 10초를 초과하는 시퀀스에서 복잡한 물리적 상호작용에 대한 Temporal Consistency는 여전히 개선이 필요

## 2. [VisPlay](https://huggingface.co/papers/2511.15661)
### Self-Evolving Vision-Language Models from Images

Self-evolving RL framework를 제안하며, 단일 VLM을 Image-Conditioned Questioner와 Multimodal Reasoner 두 역할로 나눕니다. 이들은 GRPO을 사용하여 공동으로 학습됩니다. Questioner는 Reasoner의 Uncertainty을 보상으로 받아 도전적인 질문을 생성하며, Reasoner는 Majority Voting으로 생성된 Pseudo-Label을 통해 학습

<div style={{textAlign: 'center'}}>
 <img src={blog_20251120_img0} style={{width: 500}} />
</div>

## 3.   What Does It Take to Be a Good AI Research Agent? Studying the Role of Ideation Diversity `meta`

AI agent가 빠르게 발전하고 있으나, Ai agent의 성공과 실패를 결정하는 핵심 요인은 명확히 밝혀지지 않음.

본 논문은 에이전트에게 기계학습 문제를 풀게하고 아이디어의 다양성이 높은 모델일수록 에이전트 성능이 향상됨을 통계적으로 확인함. 다양성 감소 싱능이 저하되었으며 특히 실행하지 못할 해법을 만드는 비중이 늠.

아이디어의 다양성은 모델이 제안하는 ML 모델 구조의 다양성의 엔트로피를 측정함. 즉, 초기에 다양한 모델을 고려할수록 다양성이 높은 것.

## 4. [MHR](https://huggingface.co/papers/2511.15586) `meta`
### Momentum Human Rig

Momentum 기반의 유연한 Rigging과 127개 관절의 상세한 포즈 파라미터 제어를 통합

나 왜 로봇이 생각나지.

## 5. [Mixture of States](https://huggingface.co/papers/2511.12207)
### Routing Token-Level Dynamics for Multimodal Generation

이거.. 다음에 정리.