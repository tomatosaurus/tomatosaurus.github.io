import blog_20251127_img0 from './asset/blog_20251127_img0.png';
import blog_20251127_img1 from './asset/blog_20251127_img1.png';

# 2025-11-27 papers review

## 1. [Latent Collaboration in Multi-Agent Systems](https://arxiv.org/pdf/2511.20639)

LLM Agent Collaboration 방식은 language 기반 소통 방식인데, 매우 비효율적.

LLM 모델 inference 과정에서 kv cache는 생각 과정의 중간 표현과도 같음.

추론 및 협업 과정을 전부 latent space에서 진행함. 그림을 보면 알 수 있듯이, reasoning 과정의 레이어별 kv cache자체를 전달.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251127_img0} style={{width: 500}} />
</div>

generated text가 아닌 latent space 를 이용해서 communication - reasoning 함.

9개의 벤치마크에서 성능과 효율성 전부 감소.
- token usage 70~80% 감소.
- inference 3~4배 빨라짐.
- 정확도 14.6% 증가.

## 2. [Harmony](https://huggingface.co/papers/2511.21579) `tencent`
### Harmonizing Audio and Video Generation through Cross-Task Synergy

Human speech와 environment soun가 포함된 audio-video generation 학습 개선.

기존 어려움.
- Fine-grained temporal alignment : 오디오와 비디오를 세밀한 시간 단위로 일치 시키기
- Holistic global style consistency
- Cross modal correspondence drift

Methhod:
- Correspondence drift 를 해결하기 위한 Cross-Task synergy 훈련 패러다임.
- Global-Local Decoupled Interaction Module: 영상 전반에 걸쳐 스타일 유지
- Synchronization-Enhanced CFG: 오디오 모달과 비디오 모달의 학습시 노이즈 제거의 alignment가 불안정하다.

## 3. [NVIDIA Nemotron Parse 1.1](https://huggingface.co/papers/2511.20478)

LLM 시대에 발맞춰 단순 OCR을 넘어 문서의 Layout, Reading Order, Semantic Classes, Tables, Formulas와 같은 풍부한 구조 정보를 end-to-end로 추출하는 모델 

## 4. [Revisiting Generalization Across Difficulty Levels](https://huggingface.co/papers/2511.21692)
### It's Not So Easy

문제의 난이도를 모델 능력 기반으로 평가하여, 총 10개의 난이도로 문제를 분류.

분류된 문제들에 대해서 LLM의 cross-difficulty generalization 능력을 측정함.

SFT를 통해 모델을 학습시켰으며, LLM은 easy-to-hard와 hard-to-easy에서 모두 cross-difficulyt generalization 능력이 거의 없음. 특히 난이도의 gap이 커질수록 더 해결능력이 떨어짐. 이를 통해서 모델 훈련 데이터는 쉬운 난이도에서 어려운 난이도까지 골고루 구성해야한다고 이야기 함.

모델의 generalization 능력에 대한 근본적인 탐구.

## 5. [Block Cascading](https://huggingface.co/papers/2511.20426) `stability` 
### Training Free Acceleration of Block-Causal Video Models 

training-free text-to-video generation acceleartion

<div style={{textAlign: 'center'}}>
 <img src={blog_20251127_img0} style={{width: 500}} />
</div>

핵시은 block cascade에서 fully denoised output을 사용하는 것이 아니라 partially denoised output을 그냥 사용해서 생성을 이어나가는 방식. multi-gpu 에서 최소 2배의 속도 향상을 확보함.