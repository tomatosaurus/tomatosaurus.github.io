import blog_20251119_img0 from './asset/blog_20251119_img0.png';

# 2025-11-19 papers review

## 1. [A Style is Worth One Code](https://huggingface.co/papers/2511.10555)
### Unlocking Code-to-Style Image Generation with Discrete Style Space

## 2. [Mitigating Label Length Bias in Large Language Models](https://huggingface.co/papers/2511.14385)

**label length bias**
- LLM 모델이 텍스트 분류 작업에서 후보 레이블 세트 중 하나를 선택할 떄, "레이블 길이" 에 편향되는 경향성.
- LLM 은 다중 토큰 레이블의 확률을 각 토큰의 조건부 확률 곱으로 계산. -> 토큰수가 많은 긴 레이블은 본질적으로 더 낮은 확률을 가짐.
- 결과적으로 모델이 짧은 레이블을 선호함.

**기존 방법**
- Length Normalization은 뻔한 대답의 확률이 너무 심하게 올라가는 또 다른 편향을 낳음.
- 또한, Calibration 방법들은 단일 토큰 레이블에만 초점을 맞춘 Solution이 많음.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251119_img0} style={{width: 500}} />
</div>

**NCC: Normalized Contextual Calibration**
- 전체 레이블 수준에서 확률을 정규화하고 보정.
- Label length normalization: 각 레이블의 다중 토큰 확률은 레이블 길이에 대해 기하 평균 $\sqrt[n]{P}$을 취한다. 
- Contextual Calibration: 내용이 없는 입력"("N/A")를 사용하여 모델의 기본 편향(Baseline Probability)를 측정.
- 최종 확률 계산: Label length normalization 과 Baseline probability 로 보정.

$$P_{\text{calibrated}}(y \mid C_k, x) = \frac{P_{\text{norm}}(y \mid C_k, x)}{P_{\text{baseline}}(y \mid C_k, x_{cf})}$$


## 3. [Φeat](https://huggingface.co/papers/2511.11270) `adobe`
### Physically-Grounded Feature Representation

기존 시각 모델들의 물리적 이해 능력 부족
- 기존 시각 모델들이 객체 분류나 분할은 잟했으나, 물리적 속성은 고려 못함.
- 물리적 속성의 예시 : 기하학적 구조, 반사율, 조명 등.

Physical Augmentation
- 기존의 전통적인 이미지 augmentation 대신, 물리적인 이미지 데이터 증강 기법 사용.
- 동일한 재질을 다른 조명과 다른 기하학적 형태로 렌더링한 이미지 쌍을 사용.
- 이데이터를 통해 모델 학습

**Peat**
- 이미지 내에서 특정 재질과 유사한 영역을 선택하는 작업에서 높은 성능. 물리적으로 정확히 동일한 물체를 잘 찾음.
- Unsupervised segmentation: 이미지 패치들을 군집화했을 떄, Peat는 재질의 질감과 반사율에 따라 영역을 구분함. 
- Robustness: 조명이나 기하학적 형태가 변해도 재질을 일관되게 인식.