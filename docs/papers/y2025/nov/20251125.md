import blog_20251125_img0 from './asset/blog_20251125_img0.png';

# 2025-11-25 papers review

## General Agentic Memory Via Deep Research

기존 LLM Agent의 Static Memory: Ahead-of-Time Compilation 방식
- Offline 에서 원시 컨텍스트를 압축하여 lightweight memory로 만들어서 기억.
- lightweight memory 기반으로 요청 처리.
- 압축으로 인한 정보 손실.

Just-in-Time Compilation 제안
- Memorizer: lightweight memory 생성. 원시 컨텍스트를 포함하는 완전한 정보는 page-store에 저장.
- Researcher: 메모리의 안내를 받아 page-store의 정보를 반복적으로 검색 및 통합하여 최적화된 컨텍스트 생성.
- 미리 문서의 키 정보를 추출하여 필요한 정보를 동적으로 검색 후 컨텍스트를 제공.

## [Budget-Aware Tool-Use Enables Effective Agent Scaling](https://huggingface.co/papers/2511.17006) `google`

tool-augmented agents는 자신의 가용한 리소스 budget을 정확히 파악하지 못해서 tool 사용시 효율이 감소. tool을 사용해서 비교적 간단한 작업만 진행됨.

적은 도구를 깊게 사용해야하는 과제에서도 이런 현상이 발생하는 것은 문제. 모델이 현재 자신이 사용할 수 있는 예산을 정확히 파악해야할 필요가 있음.

모델에게 실시간 예산 상황을 알려주는 경량 플러그인을 도입. 이를 바탕으로 전체 계획 및 검증 전략을 동적으로 조절하는 고급 프레임워크를 개발함.
- 현재 예산을 고려해서 매 답변 생성 시, dig deeper 또는 pivot(새로운 시도) 사이에서 결정함.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251125_img0} style={{width: 500}} />
</div>

Tool-call budget을 고려하는 새로운 연구 방향 제안. Unified Cost Metrics 제안하고 31.3% 의 절감 효과를 보여줌.

## [PRINTS](https://arxiv.org/pdf/2511.19314)
### Reward Modeling for Long-Horizon Information Seeking