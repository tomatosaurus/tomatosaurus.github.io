import blog_20251104_img0 from './asset/blog_20251104_img0.png';
import blog_20251104_img1 from './asset/blog_20251104_img1.png';
import blog_20251104_img2 from './asset/blog_20251104_img2.png';
import blog_20251104_img3 from './asset/blog_20251104_img3.png';

# 2025-11-04 papers review

## 1. [Every Activation Boosted](https://huggingface.co/papers/2510.22115)
### Scaling General Reasoner to 1 Trillion Open Language Foundation

`Inclusion AI`에서 제안하는 **Ling 2.0** 모델.

MOE with high-sparsity 사용.

## 2. [World Simulation with Video Foundation Models for Physical AI](https://huggingface.co/papers/2511.00062) `nvidia`

로봇이나 자율주행차와 같은 Physical AI 시스템은 실제 환경에서 훈련하기 어려워서, **World sSimulator**의 수요가 높다. 
- 실제 물리 세계를 대체할 수 있는 고품질의 가상 환경 시뮬레이터 필요.

Flow-based 비디오 월드 모델 **Cosmos-Predict-2.5** 제안.

Curated Video Clip 0.2B개로 선별. Physical AI에 특화된 VLM인 Cosmo-Reason1을 텍스트 인코더로 사용해서 더 풍부한 Captioning 데이터 생성.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251104_img0} style={{width: 500}} />
</div>

모델 학습
- Diffusion Transformer 구조 기반.
- relative positional embeddings 사용.
- Elucidated Diffusion Model 대신 Flow matching 방식 사용.
  - Cosmos-Predict1 모델이 사용한 EDM 방식은  diffusion 속도는 시간에 맞춰 일정. 표준 가우시안 기반 에러 제거.
  - Flow matching 방식을 도입한 Cosmos-Predict2.5 모델은 네트워크가 diffusion 과정을 속도에 맞춰 생성함.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251104_img1} style={{width: 500}} />
</div>

## 3. [Towards Universal Video Retrieval](https://huggingface.co/papers/2510.27571) `alibaba`
### Generalizing Video Embedding via Synthesized Multimodal Pyramid Curriculum

기존 비디오 검색 패러다임은 Coarse-grained 텍스트 검색에 편향되어 있음. Fine-grained, Long-context, composed 쿼리 기반 비디오 검색 능력을 갖춘 모델 필요.

- 16개 데이터셑으로 '보편성' 확보된 벤치마크 구축
- 진단 결과에 기반해 고품질 데이터 합성
  - Multi-granular Quality Control: 원본 데이터에서 노이즈 제거.
  - Multi-dimensional Information Enrichment: MLLM을 이용해서 기존 정보로부터 고품질 캡션 신규 생성.
  - Multimodal Task Extending: 실제 검색 시나리오에 필요한 다양한 작업 형식 데이터 합성.
- Modality Pyramid 커리큘럼을 사용해 모델 학습.
  - Modality Pyramid 커리큘럼: fundamental data -> Domain specific data로 학습하는 피라미드 형태 학습 워크 플로우 사용.

<div style={{textAlign: 'center'}}>
 <img src={blog_20251104_img2} style={{width: 500}} />
</div>

<div style={{textAlign: 'center'}}>
 <img src={blog_20251104_img3} style={{width: 500}} />
</div>

기존 모델들이 신규 벤치마크에서 잘 동작하지 않음 + 새로 학습한 모델이 신규 벤치마크에서 좋은 성능 보이는 것 확인.

요즘 시대에 문제를 해결하는 법, 프레임워크 자체에 의미가 있다고 생각됨.

## 4. [Do Vision-Language Models Measure Up?](https://huggingface.co/papers/2510.26865)
### Benchmarking Visual Measurement Reading with MeasureBench

VLM은 복잡한 추론 작업에서는 좋은 성능을 보이지만, 온도계의 눈금 읽기와 같은 단순하고 세밀한 작업에서는 놀라울 정도로 낮은 성능을 보임.

이는 industry level에서는 꽤 심각한 문제. gemini-2.5-pro조차 30.3% 정도 정확도에 그침. 

계측 장비 기준, 모델들은 단위를 읽는 OCR 성능은 매우 좋았음. 그러나 포인터, 액체의 위치와 같은 지침의 정확한 위치를 인지하지 못한다.

특히 복합장비에 있어서는 0% 의 정확도임.    

## 5. [Data-Efficient RLVR via Off-Policy Influence Guidance](https://huggingface.co/papers/2510.26491)

RLVR 학습에서 데이터 선택 효율성을 높이려는 논문.

Influence Function을 이용해 각 데이터가 학습 목표에 얼마나 기여하는지 추정. LLM의 online rollout cost가 너무 크기 떄문에, 사전 수집된 offline trajectory를 사용하는 off-policy influence estimation을 도입.

결과적으로 7B 모델까지의 실험에서 훈련을 크게 효율화시킴. 

1) 값비싼 실시간 rollout 없이 데이터 영향력을 추정하는 offline influence estimation
2) 고차원 gradient를 효율적으로 압축하는 sparse random projection
3) 두 기술을 결함한 새로운 RLVR 학습 프레임워크 제안.
