import blog_20251114_img1 from './asset/blog_20251114_img1.png';

# 2025-12-08 papers review


사이드 프로젝트로 며칠 여유가 없어 논문 정리를 못했다. 논문 정리 자동화를 만드는게 최종 목표였는데 요즘 단초를 잡은 것 같다. 나는 단순히 내용 정리가 아니라 인사이트와 핵심을 잘 찌르는 논문 정리를 하고 싶은데 사실 내 능력은 부족하다. 그런데 최근 링크드인에서 능력자들의 논문 정리를 보면서 저 글들을 활용해야겠다는 생각이 들었다.

## 1. [Native Parallel Reasoner](https://huggingface.co/papers/2512.07461)
### Reasoning in Parallelism via Self-Distilled Reinforcement Learning

모델에게 병렬 추론 능력을 스스로 개발할 수 있도록 함.

## 2. [DoVer](https://huggingface.co/papers/2512.06749) `microsoft`
### Intervention-Driven Auto Debugging for LLM Multi-Agent Systems

기존 multi-agent 시스템의 오류 복구는 로그 분석에 집중해옴. 하지만 이는 실제로 동작할지 알 수 없는 가설을 세우며 딘일 단계 분석 능력이 약함. Agent가 상황과 상관없는 해결방법을 제시하고 실행해봐도 잘 안되는 경험이 있을 것.

본 논문은 실제 시스템 복구에 집중하는 attribution 시스템을 제안. 시스템이 성공할 때까지 구체적으로 해야하는 작업을 업데이트하고 , 해당 작업을 통해 작업 목표를 달성했는지 평가함.

## 3. [Scaling Zero-Shot Reference-to-Video Generation](https://huggingface.co/papers/2512.06905) `meta`

데이터 레시피가 중요한 논문. zero-shot R2V를 생성함.

메타의 논문 정체성이 명확한 방향성을 가지고 있다. 관건은 LLM에 집중하고 있는 다른 기업에 비해 명확한 차이를 벌릴 수 있을까. 비디오 분야에서도 구글과 챗지피티가 괄목한 성과를 내고 있는 것 같지만 메타가 집중하고 있는 분야는 비디오 생성과는 명확한 차이가 있따.

## 4. [Distribution Matching Variational AutoEncoder](https://huggingface.co/papers/2512.07778) `tencent`

생성 모델의 잠재 벡터 분포는 모델의 이미지 이해, 생성 , 재구성 품질에 직접적으로 연관됨.

기존 모델들이 사용하던 방식은 Gaussian 구조를 상정했고, 구조의 제약이 강했음. 

즉 전역적인 분포의 형태를 더 잘 맞춰줄 필요가 있었다는 것. 저자들이 찾아보니 self super-vised learned feature의 분포가 가장 우수했음. 본질적으로 우수한 클러스터링 구조를 가지고 있기 떄문에.

제안되는 방법인 **DMVAE**이 구조를 잠재 공간에 성공적으로 복제하여 후속 생성 모델링의 복잡도를 낮춘다.

## 5. [Rethinking Training Dynamics in Scale-wise Autoregressive Generation](https://huggingface.co/papers/2512.06421) `adobe`



## 6. [Beyond Token-level Supervision](https://huggingface.co/papers/2512.06533)
### Unlocking the Potential of Decoding-based Regression via Reinforcement Learning

Decoding-based regression 이 가지고 있는 잠재력을 강화학습을 통해 실현.

개별 토큰 수준의 목표가 아니라 전체 시퀀스 수준의 보상  신호를 도입. 