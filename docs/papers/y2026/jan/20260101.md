# 2026-01-01 papers review

happy new year. 

## 1. [Youtu-LLM](https://huggingface.co/papers/2512.24618) `tencent`
### Unlocking the Native Agentic Potential for Lightweight Large Language Models

https://huggingface.co/collections/tencent/youtu

모델을 사용해볼 수 있고 오픈 소스다. web-agent 구축이나 claude code 에서 당장 사용할 수 없지만 빠르게 열리지 않을까? 

기존 LLM agent 모델은 매우 무거움. 경량화된 모델이 있지만 이는 distillation 또는 Instruction tuning에 의존하여 native agentic capability, 내재적인 인지 능력이 부족함.

이는 기존 경량화 모델이 문제 해결 과정을 체계적으로 학습하지 못했기 때문인데, 데이터 대규모 구축이 어려움. 대형 모델의 경우 Reinforcement learning 을 적극적으로 활용함.

반면 경량 모델은 1) rollout 과정에서 연산 정밀도로 인한 학습 불안정, 2) 모델 자체의 인지능력이 부족하다는 통념 하에 Instruction tuning - 두 가지 이슈로 충분히 고도화되지 못했음.

논문에서는 먼저 고품질, 대규모의 tragectory 데이터를 구축함. 그리고 SFT와 RL을 전부 학습시켜 2B 크기 모델의 성능을 크게 끌어올림.

특히 Reinforcement Learning 과정에서 학습의 불안정성과 distribution shift의 영향을 줄이기 위해 다양한 테크닉을 사용함.